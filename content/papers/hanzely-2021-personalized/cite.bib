@article{Hanzely2021Personalized,
 abstract = {We study the optimization aspects of personalized Federated Learning (FL). We develop a universal optimization theory applicable to all convex personalized FL models in the literature. In particular, we propose a general personalized objective capable of recovering essentially any existing personalized FL objective as a special case. We design several optimization techniques to minimize the general objective, namely a tailored variant of Local SGD and variants of accelerated coordinate descent/accelerated SVRCD. We demonstrate the practicality and/or optimality of our methods both in terms of communication and local computation. Lastly, we argue about the implications of our general optimization theory when applied to solve specific personalized FL objectives.},
 archiveprefix = {arXiv},
 author = {Filip Hanzely and Boxin Zhao and Mladen Kolar},
 eprint = {2102.09743},
 file = {:http\://arxiv.org/pdf/2102.09743v1:PDF},
 groups = {MyPapers},
 journal = {arXiv: 2102.09743},
 keywords = {cs.LG},
 month = {February},
 primaryclass = {cs.LG},
 title = {Personalized Federated Learning: A Unified Framework and Universal Optimization Techniques},
 year = {2021}
}

